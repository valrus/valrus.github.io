name: Fetch and Commit robots.txt
# https://darkvisitors.com/docs/robots-txt

on:
  schedule:
    - cron: "55 2 * * *"

jobs:
  fetch-and-commit:
    runs-on: ubuntu-latest

    steps:
    - name: Checkout code
      uses: actions/checkout@v3

    - name: Configure Git
      run: |
        git config user.name "github-actions"
        git config user.email "github-actions@github.com"

    - name: Fetch robots.txt
      env:
        ACCESS_TOKEN: ${{ secrets.DARK_VISITORS_ACCESS_TOKEN }}
      run: >
        curl -X POST https://api.darkvisitors.com/robots-txts
          -H 'Authorization: Bearer ${ACCESS_TOKEN}'
          -H 'Content-Type: application/json'
          -d '{
            "agent_types": [
              "AI Data Scraper",
              "Undocumented AI Agent"
            ],
            "disallow": "/"
          }'
          -O robots.txt

    - name: Commit and push robots.txt
      run: |
        git add robots.txt
        git commit -m "Update robots.txt from darkvisitors API"
        git push
