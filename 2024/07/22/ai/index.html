<!DOCTYPE html>

<html xmlns="https://www.w3.org/1999/xhtml" xml:lang="en" lang="en">
  <head>
    


    <title>small clever rooms: Why I Don't Like “AI”</title>
    
      <meta http-equiv="content-type" content="text/html;charset=utf-8" />
      <link rel="icon" type="image/png" href="/assets/images/favicon.png" />
      <link rel="shortcut icon" type="image/png" href="/assets/images/favicon.png" />
      <link rel="stylesheet" type="text/css" href="/assets/css/colors.css" />
    
    <link rel="stylesheet" type="text/css" href="/assets/css/room.css" />
    <link rel="stylesheet" type="text/css" href="/assets/css/tufte-css/tufte.css" />

<link rel="stylesheet" type="text/css" href="/assets/css/blogpost.css" />

<link rel="stylesheet" href="/assets/css/bytebox.css" type="text/css" media="screen" />
<script src="/assets/js/bytebox.min.js" type="text/javascript"></script>

  </head>

  <body>
    

    <main>
        <nav class="navigation">
            
                <h1>
                    <a class="sitename" href="/">small clever rooms</a>
                </h1>
                
                    <ul class="navigation-list">
                        
                        
                        
                            
                                <li>
                                    <a href="/livingroom/">
                                        «
                                        living room
                                    </a>
                                </li>
                            
                        
                            
                                <li>
                                    <a href="/studio/">
                                        
                                        studio
                                    </a>
                                </li>
                            
                        
                            
                                <li>
                                    <a href="/study/">
                                        
                                        study
                                    </a>
                                </li>
                            
                        
                            
                                <li>
                                    <a href="/workshop/">
                                        
                                        workshop
                                    </a>
                                </li>
                            
                        
                            
                                <li>
                                    <a href="/outside/">
                                        
                                        outside
                                    </a>
                                </li>
                            
                        
                    </ul>
                
            
        </nav>
        
<article>
    <h1>Why I Don't Like “AI”</h1>
    
    <p>Since circumstances in my life require that I spend way more time
than I want thinking about AI, I figure at least I can maybe get a blog
post out of it.</p>
<section id="its-not-ai" class="level2">
<h2>It’s Not “AI”</h2>
<p>Okay, so first off: I don’t even like to refer to the recent in-vogue
text and image generation tools as “AI.” I think it’s a poorly-defined
term that is used more to evoke associations in people’s brains than to
be an accurate representation of the technology we have in front of us.
Throughout this rant I will refer to things like ChatGPT as “LLMs,” for
“Large Language Models.” Because if LLMs are AI, so is autocorrect on
your phone. So is every other “chat bot” that uses keyword matching to
try to direct you to a website’s help pages to run interference on
letting you talk to a human.</p>
</section>
<section id="its-boosters-are-misanthropic" class="level2">
<h2>Its Boosters Are Misanthropic</h2>
<p>Here’s Sam Altman, OpenAI’s CEO, <a
href="https://deadsimpletech.com/blog/altman_dunce">being a
dunce</a>:</p>
<figure>
<img src="/assets/images/posts/ChatGPT/stochastic-parrots-2.png"
title="Sam Altman on Twitter, 11 Nov 2022: &quot;what happens when we realize we were just stochastic parrots all along?&quot;"
alt="God this guy sucks" />
<figcaption aria-hidden="true">God this guy sucks</figcaption>
</figure>
<figure>
<img src="/assets/images/posts/ChatGPT/stochastic-parrots-1.png"
title="Sam Altman on Twitter, 4 Dec 2022: &quot;i am a stochastic parrot, and so r u&quot;"
alt="This guy sucks so fucking bad" />
<figcaption aria-hidden="true">This guy sucks so fucking
bad</figcaption>
</figure>
<p>These quotes are a reference to a 2021 paper<span
class="sidenote-wrapper"><label for="sn-0" class="margin-toggle sidenote-number"></label><input type="checkbox" id="sn-0" class="margin-toggle"/><span
class="sidenote">Emily M. Bender, Timnit Gebru, Angelina McMillan-Major,
and Shmargaret Shmitchell. 2021. On the Dangers of Stochastic Parrots:
Can Language Models Be Too Big? 🦜. In Conference on Fairness,
Accountability, and Transparency (FAccT ’21), March 3–10, 2021, Virtual
Event, Canada. ACM, New York, NY, USA, 14 pages.
https://doi.org/10.1145/3442188.3445922<br />
<br />
</span></span> about LLMs. In it, its co-authors Emily Bender and Timnit
Gebru define “stochastic parrot” thus:</p>
<blockquote>
<p>…an LM is a system for haphazardly stitching together sequences of
linguistic forms it has observed in its vast training data, according to
probabilistic information about how they combine, but without any
reference to meaning: a stochastic parrot.</p>
</blockquote>
<p>In this context, what Altman is saying is clear: when you have
thoughts and feelings and use them to express yourself with language,
all you’re <em>really</em> doing is putting one word in front of another
in a way that’s probabilistically consistent with the vast amount of
other language you’ve been exposed to in your life.</p>
<p>Here’s some text I probabilistically generated with Sam Altman’s
claims and the definition of “stochastic parrot” as input: not only is
this wrong, it fucking sucks, and I hate it. I know it is wrong, and I
know I hate it, because I read it and I feel disgust as a somatic
experience not unlike mild nausea, along with an involuntary twist in my
face that I have to consciously suppress and involuntary tenseness in my
muscles that I have to consciously relax. My reaction is not just the
result of neurons firing in response to linguistic entities. I feel it
in my body. And even if I don’t choose to assemble my thoughts into
words as I’m doing now, the feeling persists. What about dance? Sport?
Can these bodily experiences and all the intuition they require to
achieve be reproduced synthetically by consuming enough training
data?<span
class="sidenote-wrapper"><label for="sn-1" class="margin-toggle sidenote-number"></label><input type="checkbox" id="sn-1" class="margin-toggle"/><span
class="sidenote">This paragraph is a patchy, inadequate survey of a
small portion of the ground covered in Siri Hustvedt’s tremendous essay
“The Delusions of Certainty,” which can be found in her book <em>A Woman
Looking At Men Looking At Women</em>. If you are unconvinced by my
single paragraph of rebuttal here, please read that essay and consider
how many of the delusional certainties discussed in it the
humans-as-stochastic-parrots claim rests on.<br />
<br />
</span></span></p>
<p>I hate not just that Altman’s unsupported claim debases the richness
of actual human experience, but that it does so in such a transparently
self-serving way. If humans are just stochastic parrots, of course,
anything they can do can be done instead by a language model, such as
those conveniently produced by Altman’s company. This minimization of
the sophistication of human experience is the counterpart of AI
fearmongering, which posits <a
href="https://openai.com/blog/our-approach-to-alignment-research">AI as
a possible “existential risk”</a> in order to make it seem more powerful
than it is. I don’t think Sam Altman really believes what he’s saying
here, but whether he does or not, it’s incredibly cynical, and it
sucks.</p>
</section>
<section id="the-hype-sucks-and-its-encroachingly-ubiquitous"
class="level2">
<h2>The Hype Sucks And It’s Encroachingly Ubiquitous</h2>
<p>The hype around LLMs has been at the level of “fever pitch” for
months that feel like years. It’s the most significant invention since
the Internet. No, since the <em>printing press.</em> No, since
<em>electricity.</em> No, seriously. In an <a
href="https://www.henryakissinger.com/articles/chatgpt-heralds-an-intellectual-revolution/">editorial
for the Wall Street Journal</a>, Henry Kissinger<span
class="sidenote-wrapper"><label for="sn-2" class="margin-toggle sidenote-number"></label><input type="checkbox" id="sn-2" class="margin-toggle"/><span
class="sidenote">Really? <em>This</em> <a
href="https://www.vox.com/2016/5/9/11640562/kissinger-pentagon-award">Henry
Kissinger?</a><br />
<br />
</span></span>, Eric Schmidt and Daniel Huttenlocher say:</p>
<blockquote>
<p>A new technology bids to transform the human cognitive process as it
has not been shaken up since the invention of printing. The technology
that printed the Gutenberg Bible in 1455 made abstract human thought
communicable generally and rapidly. But new technology today reverses
that process. Whereas the printing press caused a profusion of modern
human thought, the new technology achieves its distillation and
elaboration. In the process, it creates a gap between human knowledge
and human understanding. If we are to navigate this transformation
successfully, new concepts of human thought and interaction with
machines will need to be developed. This is the essential challenge of
the Age of Artificial Intelligence.</p>
</blockquote>
<p>Marc Andreessen <a
href="https://a16z.com/ai-will-save-the-world/">says</a>:</p>
<blockquote>
<p>The stakes here are high. The opportunities are profound. AI is quite
possibly the most important – and best – thing our civilization has ever
created, certainly on par with electricity and microchips, and probably
beyond those.</p>
</blockquote>
<p>This doesn’t make any fucking sense! You can’t run a so-called AI
without electricity and microchips! <em>How can AI be more important
than the things its very existence depends on?</em> But then, of course,
Andreessen is a venture capitalist who invests in these technologies. So
perhaps he’s not a wholly objective and impartial observer here. But so
because what we call a “free” country is actually largely controlled by
the whims of people like Marc Andreessen, it’s apparently become
mandatory for every company on earth to cram some “AI” functionality
that no one asked for into their already rapidly-enshittifying product,
in order to…? Attract VC funding? Get a bump in their stock price? If I
were a more inquisitive or cynical person I might have a better
understanding of whatever asinine capitalist incentives are at play
here. But we’re just coming off <em>yet another</em> record-breaking
heatwave where I live, so I just can’t bring myself to give a shit about
capitalist incentives, because look where they’ve gotten us.</p>
<p>On the other side of the coin, now that LLMs are in the hands of The
People, they’re rapidly using them to flood the entire internet with
dubiously-accurate laundered plagiarism. The uselessness of the internet
for obtaining actual information has been intensifying for years, what
with Google gradually turning their search engine into an advertisement
delivery engine and the proliferation of SEO spam. But LLMs are going to
make this a hundred times worse. Indeed, they’re already doing so.</p>
</section>
<section id="its-obsequity-is-annoying-and-its-prose-is-vapid"
class="level2">
<h2>Its Obsequity Is Annoying And Its Prose Is Vapid</h2>
<p>Maybe I wouldn’t mind seeing LLM-extruded text everywhere if it were
actually pleasant or interesting to read. But it’s not. It’s invariably
a flavorless beige paste, as dead on the page as the entity that
produced it.</p>
<p>Insofar as ChatGPT can be said to have a personality, it is
deferential to the point of obsequity. ChatGPT backs down immediately
and totally when challenged. Recently I used it to provide me an
<code>rsync</code> <a href="https://manpages.org/rsync">command</a> to
transfer some files to my NAS, and it gave me a working command with no
issue. Pretty cool!<span
class="sidenote-wrapper"><label for="sn-3" class="margin-toggle sidenote-number"></label><input type="checkbox" id="sn-3" class="margin-toggle"/><span
class="sidenote">I never had any doubt that this would work. GPT is
trained on the internet, which is replete with nerds talking about their
nerd shit. Nerds love nothing more than to explain things. As evidence,
see: this whole-ass web site<br />
<br />
</span></span> The network connection got interrupted, and I asked how
to resume the transfer. ChatGPT gave me another command with the
<code>--partial</code> flag, and that worked too. Also pretty cool! Then
I told it that that the <code>--partial</code> flag that I had just
successfully used doesn’t actually exist. It readily agreed and
“corrected” itself:</p>
<figure>
<img src="/assets/images/posts/ChatGPT/rsync-partial.png"
title="me: &quot;The `--partial flag doesn&#39;t actually exist.&quot; chatgpt: &quot;I apologize for the incorrect information provided. You&#39;re right, the --partial flag does not exist in rsync. I apologize for the confusion caused.&quot;"
alt="I guess ‘I apologize for the confusion caused’ could refer to ChatGPT’s." />
<figcaption aria-hidden="true">I guess ‘I apologize for the confusion
caused’ could refer to ChatGPT’s.</figcaption>
</figure>
<p>It’s hard to credit ChatGPT with a lot of new or original inventions,
considering that it’s built completely off the stolen text of the actual
humans who preceded it, but it seems to have invented a new kind of
rhetorical technique which I’m pithily naming the “apology sandwich.” I
view anyone who actually <em>wants</em> to be groveled at like this with
extreme suspicion, but it does seem to be designed to take advantage of
<a
href="https://papers.ssrn.com/sol3/papers.cfm?abstract_id=3762223">our
tendency to anthromorphize</a>, to lead us to think these things are
actually intelligent and even sentient. They’re not.</p>
<p>Or see <a
href="http://www.briggeman.org/wordpress/posts/talking-chatgpt-with-chatgpt/">this
chat</a> where Jason Briggeman presses it on why it fails to generate a
limerick that scans when a poetic form with very strict and clear
parameters for meter and rhyme should be right up a piece of software’s
alley. One half expects it to respond to a correction with “pwease i am
just a smol chatbot who is twying its vewwy best.” I would almost prefer
<a
href="https://www.theverge.com/2023/2/15/23599072/microsoft-ai-bing-personality-conversations-spy-employees-webcams">Bing
Chat’s amoral, hostile intransigence</a> if not for fear that it would
spawn a thousand hysterical thinkpieces about “alignment<span
class="sidenote-wrapper"><label for="sn-4" class="margin-toggle sidenote-number"></label><input type="checkbox" id="sn-4" class="margin-toggle"/><span
class="sidenote">“Alignment” is the term for making sure that some
imaginary sentient AI’s incentives are “aligned” with humanity’s so that
it doesn’t end up, like, launching nukes or <a
href="https://en.wikipedia.org/wiki/Instrumental_convergence#Paperclip_maximizer">turning
us all into paperclips</a> or whatever. Pure science fiction, but that’s
the mode the kind of people who write about “alignment” want you to be
operating in.<br />
<br />
</span></span>” for every day it was allowed to continue running.</p>
</section>
<section id="its-boosters-dont-give-a-shit-about-consent"
class="level2">
<h2>Its Boosters Don’t Give A Shit About Consent</h2>
<p>It seems like barely a day goes by when I don’t read about some
company adding a clause to their user agreement saying they’re going to
be training LLMs on your data. This training is never opt-in. It’s
enabled by default, and it will be happening unless you (a) find out
about it and (b) wade through the inevitable thicket of <a
href="https://www.deceptive.design/types/obstruction">dark patterns</a>
lovingly grown between you and the setting to turn it off. Assuming
there is one.</p>
<p>But of course, why wouldn’t companies that use LLMs do this? <a
href="https://artisticinquiry.org/AI-Open-Letter">Using people’s work
without their consent</a> is literally the foundation upon which LLMs
are built. So of course they’re going to see nothing wrong with silently
opting-in their users, or <a
href="https://rknight.me/blog/perplexity-ai-robotstxt-and-other-questions/">ignoring
decades-old web scraping conventions</a>, or <a
href="https://www.metafilter.com/204762/Taylor-and-Francis-sells-access-to-research-material-to-Microsoft-AI">selling
their users’ data</a> <a
href="https://arstechnica.com/ai/2024/05/openai-will-use-reddit-posts-to-train-chatgpt-under-new-deal">for
LLM training</a>. It’s the most important thing since electricity!
<em>Why do you hate progress???</em></p>
</section>
<section id="so-what-am-i-even-fucking-doing-here" class="level2">
<h2>So What Am I Even Fucking Doing Here</h2>
<p>“Other people’s work,” in the last paragraph, includes mine, of
course:</p>
<figure>
<img src="/assets/images/posts/ChatGPT/itme.png"
title="A search for my domain name in the C4 dataset used by Google to train LLMS. I have helpfully if nonconsensually provided them 17,000 tokens, one hundred thousandth of a percent of the dataset."
alt="I can see my house from here" />
<figcaption aria-hidden="true">I can see my house from here</figcaption>
</figure>
<p>And so it’s like, why keep posting on the internet if these assholes
are just going to scrape it into their insatiable maw, along with a
million other actual people’s actual hard work, to be shat out in an
unrecognizable<span
class="sidenote-wrapper"><label for="sn-5" class="margin-toggle sidenote-number"></label><input type="checkbox" id="sn-5" class="margin-toggle"/><span
class="sidenote">(though, come to think of it, <em>recognizable</em>
would be even worse)<br />
<br />
</span></span> homogeneous, anodyne slurry? I don’t think I’m a
<em>great</em> writer but I think I’m OK at it, and I can’t put my
feelings about this any better than maya, whose <a
href="https://maya.land/">maya.land</a> is the kind of intensely unique
and flavorful and <em>human</em> old-school personal website that the
web should be aspiring to—</p>
<blockquote>
<p>This site has been too much of an experiment for me to claim now that
I have a grand theory about it, about similar sites – but certainly by
now I have instincts, feelings… …and making my writing available for
automated summarization? So someone can sell ads by a depersonalized
version of my stuff? The feeling is nausea.</p>
</blockquote>
<p>—in her incredibly relatable “<a
href="https://maya.land/monologues/2023/02/14/mr-openai-i-dont-feel-so-good.html">mr.
openai i don’t feel so good</a>.” Or, to TL;DR the very good <a
href="https://v21.io/blog/how-to-find-things-online">How To Find Things
Online</a>, which you should also actually R, What Even Is The Point
Anymore.<span
class="sidenote-wrapper"><label for="sn-6" class="margin-toggle sidenote-number"></label><input type="checkbox" id="sn-6" class="margin-toggle"/><span
class="sidenote">I <em>know</em> it had already been over a year since
my last blog post when ChatGPT arrived on the scene. But it’s the
<em>principle</em> of the thing.<br />
<br />
</span></span></p>
<p>Maybe I am engaged in the valuable, noble act of <a
href="https://lmnt.me/blog/building-a-stronger-web.html">Building A
Stronger Web Without AI</a>. Maybe by linking to <a
href="https://www.baldurbjarnason.com/archive/">real humans</a> using
their hard-earned brain cells to write thoughtful words on the internet,
I can help make a web that feels like a <em>web</em>, interconnected and
constructed by individuals, one not dependent on the whims of
multi-billion-dollar advertising companies. Maybe I just want to <a
href="https://wilnichols.com/dumb-thoughts-on-dumber-ai/">add my
voice</a> to the others saying this stuff is bad, morally and
aesthetically. Maybe since it contributed to taking away what little
wind I had in my sails for blogging in the last couple years, it seemed
only suitable that I use my first post back to slag it off. Anyway, here
you go, ChatGPT. Go tell people how much I think you suck.</p>
</section>

</article>

        <footer>
            <div id="post-tags">
    
        Tagged <span>&raquo;</span>
        
            <code><a href="/livingroom/tags/ai/">ai</a></code> • 
        
            <code><a href="/livingroom/tags/rant/">rant</a></code>
        
    
</div>
<div id="adjacent-posts">
    <div id="older-post">
        
        <div class="arrow">←</div>
        <div class="older-link">
            <a href="/2023/02/05/ducks_newburyport/"><em>Ducks, Newburyport</em></a>
        </div>
        
    </div>
    <div id="newer-post">
        
        <div class="newer-link">
            <a href="/2025/04/30/little_things/">Exterior // Interior</a>
        </div>
        <div class="arrow">→</div>
        
    </div>
</div>

            
            <div class="colophon">
                
                    <p>
                        Contact me via <a href="mailto:ian@mccowan.space">email</a>.
                        I'm also on <a href="https://joinmastodon.org/">Mastodon</a>
                        as <a rel="me" href="https://icosahedron.website/@valrus">@valrus@icosahedron.website</a>,
                        and on <a rel="me" href="https://github.com/valrus">GitHub</a>.
                    </p>
                
            </div>
        </footer>
    </main>

<script type="text/javascript">bytebox.init();</script>

  </body>
</html>